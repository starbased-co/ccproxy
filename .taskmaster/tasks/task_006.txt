# Task ID: 6
# Title: Implement Claude Wrapper Script with Auto-Managed CCProxy
# Status: pending
# Dependencies: 2, 5
# Priority: high
# Description: Create a Python CLI wrapper that transparently starts/reuses a LiteLLM+CCProxy instance, forwards all user-supplied "claude" arguments through the proxy, and shuts the proxy down when no Claude sessions remain.
# Details:
1. Placement & Packaging
   • Add module ccproxy.claude_wrapper and expose an entry-point "claude" via pyproject.toml so users simply run "claude ...".
   • Keep the original Anthropic CLI semantics: forward every CLI arg/flag untouched.

2. Runtime Flow
   a) Process Co-ordination
      • Acquire a file lock (e.g., fasteners.InterProcessLock at ~/.ccproxy/claude.lock) to serialize start/stop decisions.
      • Inside the lock read ~/.ccproxy/claude_proxy.json containing {pid, port, start_time, refcount} if it exists.
   b) Proxy Reuse or Spawn
      • Validate the recorded PID is alive and listening; if so, increment refcount and continue.
      • Otherwise choose a free port (socket.bind(('',0)).getsockname()[1]), construct env vars (LITELLM_PROXY_PORT, HTTP_PROXY, HTTPS_PROXY, OPENAI_BASE_URL, etc.) and launch:
        subprocess.Popen([
          sys.executable,
          "-m","ccproxy.run_proxy",
          "--port", str(port),
          "--handler","ccproxy.handlers.CCProxyHandler"
        ], stdout=logfile, stderr=logfile, env=clean_env)
      • Persist new pid/port/refcount=1 to claude_proxy.json.
   c) Execute Real Claude
      • Build env for the child process: inherit current env + proxy vars so Anthropic CLI routes through LiteLLM.
      • Use subprocess.call(["anthropic","..."], env=wrapped_env, pass_fds=[]).
   d) Shutdown Logic (finally block)
      • Re-acquire lock, decrement refcount; if 0 send SIGINT then SIGTERM (5-second grace) to proxy pid and delete state file.

3. Cross-Platform & Robustness
   • Use psutil where available for PID liveness; fall back to os.kill on POSIX and ctypes on Windows.
   • Redirect proxy stdout/stderr to ~/.ccproxy/proxy.log; rotate daily with logging.handlers.RotatingFileHandler.
   • Never print API keys; redact with **** if the user enables --verbose on wrapper.
   • Respect existing user proxy settings by only overriding for Anthropic-specific variables.

4. Configuration Hooks
   • Honour CC_PROXY_CONFIG, CC_PROXY_PORT, and CC_PROXY_LOG env vars for power users.
   • Consume Configuration Manager (Task 2) to load yaml/env overrides if present so the spawned proxy picks up the same routing table.

5. Documentation Stub
   • Add a section in docs/usage.md: “Running the Anthropic CLI via ccproxy” with examples and troubleshooting tips.

# Test Strategy:


# Subtasks:
## 1. Productionize: Performance, Security, and Monitoring Hardening [pending]
### Dependencies: 6.7, 6.8, 6.9, 6.10
### Description: Finalize production readiness with benchmarking, rate limiting, abuse prevention, and deployment best practices.
### Details:
Benchmark concurrent request handling (use locust or wrk). Implement rate limiting with slowapi or similar. Harden HTTP endpoints (CORS, timeouts, error handling). Document deployment (Dockerfile, k8s manifests). Ensure logging and metrics are production-grade. Prepare for future extensibility (plugin hooks).
