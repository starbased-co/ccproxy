# See https://docs.litellm.ai/docs/proxy/configs
model_list:
  # Default model for regular use
  - model_name: default
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514

  # Background model, see: https://docs.anthropic.com/en/docs/claude-code/costs#background-token-usage
  - model_name: model_name
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022

  # Thinking model for complex reasoning (request.body.think = true)
  - model_name: think
    litellm_params:
      model: anthropic/claude-opus-4-20250514

  # Large context model for >60k tokens (threshold configurable in ccproxy.yaml)
  - model_name: token_count
    litellm_params:
      model: gemini/gemini-2.5-pro

  # Web search model for execution when the WebSearch tool is present
  - model_name: web_search
    litellm_params:
      model: gemini/gemini-2.5-flash

litellm_settings:
  callbacks: ccproxy.handler
